{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# üèÜ Challenge 1: Data Preparation for Training\n",
    "\n",
    "**Difficulty**: ‚≠ê‚≠ê (Intermediate) | **Time**: 45-60 minutes\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "\n",
    "By completing this challenge, you will:\n",
    "1. Understand the data format required by TwinWeaver\n",
    "2. Configure the pipeline for different prediction tasks\n",
    "3. Generate training splits from patient timelines\n",
    "4. Convert structured data to instruction-tuning format\n",
    "\n",
    "## üìã Rules\n",
    "- Complete all `# TODO:` sections\n",
    "- Answer quiz questions before proceeding\n",
    "- Run checkpoint cells to validate your solutions\n",
    "- **No peeking at the original tutorial!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: Understanding the Data\n",
    "\n",
    "Before we start coding, let's understand what data we're working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from twinweaver import (\n",
    "    DataManager,\n",
    "    Config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the example data\n",
    "df_events = pd.read_csv(\"../example_data/events.csv\")\n",
    "df_constant = pd.read_csv(\"../example_data/constant.csv\")\n",
    "df_constant_description = pd.read_csv(\"../example_data/constant_description.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "### üîç Exercise 1.1: Explore the Data\n",
    "\n",
    "Before configuring the pipeline, you need to understand your data. Explore the three dataframes to answer the quiz questions below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Explore df_events - what columns does it have? What are the unique event categories?\n",
    "# Write your exploration code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Explore df_constant - what patient-level information is available?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Explore df_constant_description - how does this map to df_constant?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "### ‚ùì Quiz 1: Data Understanding\n",
    "\n",
    "Answer these questions based on your exploration:\n",
    "\n",
    "**Q1.1**: What column in `df_events` contains the type of medical event (lab, drug, condition, etc.)?\n",
    "\n",
    "**Q1.2**: List all unique event categories in the dataset:\n",
    "\n",
    "**Q1.3**: How many unique patients are in the dataset?\n",
    "\n",
    "**Q1.4**: What column in `df_constant` could be used to calculate a patient's age?\n",
    "\n",
    "*Write your answers in the cell below:*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "**Your Answers:**\n",
    "\n",
    "Q1.1: \n",
    "\n",
    "Q1.2: \n",
    "\n",
    "Q1.3: \n",
    "\n",
    "Q1.4: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: Configuration Challenge\n",
    "\n",
    "Now you need to configure the TwinWeaver pipeline. This is where understanding your data pays off!\n",
    "\n",
    "### üéØ Your Task\n",
    "\n",
    "Configure the pipeline to:\n",
    "1. Split patient histories around **Lines of Therapy** (treatment changes)\n",
    "2. Forecast **lab values** into the future\n",
    "3. Predict time-to-event for **death** and **progression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config()\n",
    "\n",
    "# TODO: Set the event category used for splitting patient timelines\n",
    "# HINT: Look at your answer to Q1.2 - which category represents treatment lines?\n",
    "config.split_event_category = None  # Replace None with the correct value\n",
    "\n",
    "# TODO: Set which event categories should be forecasted as time-series\n",
    "# HINT: We want to predict future lab values\n",
    "config.event_category_forecast = None  # Replace None with a list\n",
    "\n",
    "# TODO: Configure time-to-event prediction targets\n",
    "# HINT: This should be a dictionary mapping event names to display names\n",
    "# Example: {\"original_name\": \"display name in prompt\"}\n",
    "config.data_splitter_events_variables_category_mapping = None  # Replace with dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "### üèÅ Checkpoint 2.1: Validate Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to check your configuration\n",
    "def validate_config_part1(config):\n",
    "    errors = []\n",
    "\n",
    "    if config.split_event_category is None:\n",
    "        errors.append(\"‚ùå split_event_category is not set\")\n",
    "    elif config.split_event_category not in df_events[\"event_category\"].unique():\n",
    "        errors.append(f\"‚ùå split_event_category '{config.split_event_category}' not found in data\")\n",
    "    else:\n",
    "        print(f\"‚úÖ split_event_category: '{config.split_event_category}'\")\n",
    "\n",
    "    if config.event_category_forecast is None:\n",
    "        errors.append(\"‚ùå event_category_forecast is not set\")\n",
    "    elif not isinstance(config.event_category_forecast, list):\n",
    "        errors.append(\"‚ùå event_category_forecast should be a list\")\n",
    "    elif any([cat not in df_events[\"event_category\"].unique() for cat in config.event_category_forecast]):\n",
    "        errors.append(\"‚ùå At least one of the event_category_forecast values not found in data\")\n",
    "    else:\n",
    "        print(f\"‚úÖ event_category_forecast: {config.event_category_forecast}\")\n",
    "\n",
    "    if config.data_splitter_events_variables_category_mapping is None:\n",
    "        errors.append(\"‚ùå data_splitter_events_variables_category_mapping is not set\")\n",
    "    elif not isinstance(config.data_splitter_events_variables_category_mapping, dict):\n",
    "        errors.append(\"‚ùå data_splitter_events_variables_category_mapping should be a dict\")\n",
    "    elif any(\n",
    "        [\n",
    "            cat not in df_events[\"event_category\"].unique()\n",
    "            for cat in config.data_splitter_events_variables_category_mapping.keys()\n",
    "        ]\n",
    "    ):\n",
    "        errors.append(\"‚ùå At least one key in data_splitter_events_variables_category_mapping not found in data\")\n",
    "    else:\n",
    "        print(f\"‚úÖ Event mapping: {config.data_splitter_events_variables_category_mapping}\")\n",
    "\n",
    "    if errors:\n",
    "        print(\"\\n\" + \"\\n\".join(errors))\n",
    "        print(\"\\nüí° Hint: Review Part 1 exploration to find the correct values\")\n",
    "    else:\n",
    "        print(\"\\nüéâ Part 2.1 Complete! Configuration looks good.\")\n",
    "\n",
    "    return len(errors) == 0\n",
    "\n",
    "\n",
    "validate_config_part1(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "### üîß Exercise 2.2: Configure Static Variables\n",
    "\n",
    "Now configure which patient demographics to include in the prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Look at df_constant columns and decide which ones to include\n",
    "# Consider: Which variables are clinically relevant for predictions?\n",
    "\n",
    "# First, explore what's available\n",
    "print(\"Available columns in df_constant:\")\n",
    "print(df_constant.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Select which constant columns to use (list of column names)\n",
    "config.constant_columns_to_use = []  # Fill in the list\n",
    "\n",
    "# TODO: Specify which column contains birth year/date for age calculation\n",
    "config.constant_birthdate_column = None  # Set the column name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: Initialize the Pipeline\n",
    "\n",
    "With configuration complete, let's initialize the data processing components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Initialize DataManager and load data\n",
    "# The DataManager needs to:\n",
    "# 1. Be created with your config\n",
    "# 2. Load the indication data (events, constant, constant_description)\n",
    "# 3. Process the indication data\n",
    "# 4. Setup unique mapping of events\n",
    "# 5. Setup dataset splits\n",
    "# 6. Infer variable types\n",
    "\n",
    "dm = DataManager(config=config)\n",
    "\n",
    "# TODO: Call the required methods in the correct order\n",
    "# dm.????\n",
    "# dm.????\n",
    "# dm.????\n",
    "# dm.????\n",
    "# dm.????"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "### üèÅ Checkpoint 3.1: Validate DataManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this to verify DataManager is set up correctly\n",
    "try:\n",
    "    n_patients = len(dm.all_patientids)\n",
    "    print(f\"‚úÖ DataManager initialized with {n_patients} patients\")\n",
    "\n",
    "    # Check if we can get patient data\n",
    "    test_patient = dm.all_patientids[0]\n",
    "    patient_data = dm.get_patient_data(test_patient)\n",
    "    print(f\"‚úÖ Successfully retrieved data for patient {test_patient}\")\n",
    "    print(f\"   - Events: {len(patient_data['events'])} rows\")\n",
    "    print(f\"   - Constant: {len(patient_data['constant'])} rows\")\n",
    "    print(\"\\nüéâ Part 3 Complete!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")\n",
    "    print(\"\\nüí° Hint: Make sure you called all DataManager methods in the correct order\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 4: Create Splitters and Converter\n",
    "\n",
    "### ‚ùì Quiz 2: Understanding Splitters\n",
    "\n",
    "Before creating the splitters, answer these conceptual questions:\n",
    "\n",
    "**Q2.1**: What is the purpose of splitting a patient's timeline? Why not use the entire history?\n",
    "\n",
    "**Q2.2**: What's the difference between `DataSplitterEvents` and `DataSplitterForecasting`?\n",
    "\n",
    "**Q2.3**: Why do we need a token budget for the converter?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "**Your Answers:**\n",
    "\n",
    "Q2.1: \n",
    "\n",
    "Q2.2: \n",
    "\n",
    "Q2.3: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Initialize DataSplitterEvents\n",
    "# This handles event prediction tasks (death, progression)\n",
    "data_splitter_events = None  # Create the splitter\n",
    "\n",
    "# TODO: Don't forget to call setup_variables() on it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Initialize DataSplitterForecasting\n",
    "# This handles continuous variable forecasting (lab values)\n",
    "data_splitter_forecasting = None  # Create the splitter\n",
    "\n",
    "# TODO: Call setup_statistics() for forecasting QA and filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Combine both splitters using DataSplitter wrapper\n",
    "data_splitter = None  # Create the combined splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Initialize ConverterInstruction\n",
    "# Parameters needed:\n",
    "# - nr_tokens_budget_total: How many tokens can the prompt be? (try 8192)\n",
    "# - config: Your configuration object\n",
    "# - dm: Your DataManager\n",
    "# - variable_stats: Statistics from forecasting splitter (optional but recommended)\n",
    "\n",
    "converter = None  # Create the converter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "### üèÅ Checkpoint 4.1: Validate Pipeline Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate all components are created\n",
    "components_valid = True\n",
    "\n",
    "if data_splitter_events is None:\n",
    "    print(\"‚ùå data_splitter_events is not initialized\")\n",
    "    components_valid = False\n",
    "else:\n",
    "    print(\"‚úÖ data_splitter_events initialized\")\n",
    "\n",
    "if data_splitter_forecasting is None:\n",
    "    print(\"‚ùå data_splitter_forecasting is not initialized\")\n",
    "    components_valid = False\n",
    "else:\n",
    "    print(\"‚úÖ data_splitter_forecasting initialized\")\n",
    "\n",
    "if data_splitter is None:\n",
    "    print(\"‚ùå data_splitter is not initialized\")\n",
    "    components_valid = False\n",
    "else:\n",
    "    print(\"‚úÖ data_splitter initialized\")\n",
    "\n",
    "if converter is None:\n",
    "    print(\"‚ùå converter is not initialized\")\n",
    "    components_valid = False\n",
    "else:\n",
    "    print(\"‚úÖ converter initialized\")\n",
    "\n",
    "if components_valid:\n",
    "    print(\"\\nüéâ Part 4 Complete! All components ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 5: Generate Training Examples\n",
    "\n",
    "Now let's generate actual training examples!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a patient to work with\n",
    "patientid = dm.all_patientids[4]\n",
    "print(f\"Working with patient: {patientid}\")\n",
    "\n",
    "# Get patient data\n",
    "patient_data = dm.get_patient_data(patientid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Generate splits from this patient's data\n",
    "# Use data_splitter.get_splits_from_patient_with_target()\n",
    "# This returns: forecasting_splits, events_splits, reference_dates\n",
    "\n",
    "forecasting_splits, events_splits, reference_dates = None, None, None  # Replace with actual call"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "### üîç Exercise 5.1: Analyze the Splits\n",
    "\n",
    "Before converting, understand what the splitter produced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Answer these questions by exploring the splits:\n",
    "# 1. How many splits were generated for this patient?\n",
    "# 2. What dates are the reference points (split dates)?\n",
    "# 3. What does each split contain?\n",
    "\n",
    "print(\"Number of splits: ???\")  # Fill in\n",
    "print(\"Reference dates: ???\")  # Fill in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Convert the first split to instruction format\n",
    "# Use converter.forward_conversion()\n",
    "# Parameters:\n",
    "# - forecasting_splits: the forecasting split for one time point\n",
    "# - event_splits: the event split for one time point\n",
    "# - override_mode_to_select_forecasting: set to \"both\"\n",
    "\n",
    "split_idx = 0\n",
    "p_converted = None  # Replace with actual conversion call"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "### üîç Exercise 5.2: Examine the Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Print and examine the instruction (input prompt)\n",
    "# What information is included? What's the structure?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Print and examine the answer (target output)\n",
    "# What format is the answer in? What predictions are being made?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "### ‚ùì Quiz 3: Output Analysis\n",
    "\n",
    "**Q3.1**: What sections can you identify in the instruction prompt?\n",
    "\n",
    "**Q3.2**: How are the forecasting predictions formatted in the answer?\n",
    "\n",
    "**Q3.3**: How are the time-to-event predictions formatted?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "**Your Answers:**\n",
    "\n",
    "Q3.1: \n",
    "\n",
    "Q3.2: \n",
    "\n",
    "Q3.3: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 6: Reverse Conversion\n",
    "\n",
    "An important capability is converting model outputs back to structured data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Use reverse_conversion to parse the answer back to structured data\n",
    "# You'll need:\n",
    "# - The answer string from p_converted\n",
    "# - The data manager (dm)\n",
    "# - The reference date for this split\n",
    "\n",
    "date = reference_dates[\"date\"][split_idx]\n",
    "return_list = None  # Call converter.reverse_conversion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Examine what the reverse conversion produced\n",
    "# What structure does return_list have? What's in each element?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "---\n",
    "## üåü Bonus Challenge 1: Custom Configuration\n",
    "\n",
    "**+15 points**\n",
    "\n",
    "Modify the configuration to predict **only drug-related events** instead of death and progression. Generate a new training example and compare the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BONUS: Implement your custom configuration here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": [
    "---\n",
    "## üåü Bonus Challenge 2: Multi-Patient Dataset\n",
    "\n",
    "**+25 points**\n",
    "\n",
    "Write a function that generates training examples for ALL patients in the dataset and returns a pandas DataFrame with columns: `patientid`, `split_idx`, `instruction`, `answer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BONUS: Implement the multi-patient dataset generator\n",
    "\n",
    "\n",
    "def generate_training_dataset(dm, data_splitter, converter):\n",
    "    \"\"\"\n",
    "    Generate training examples for all patients.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame with columns: patientid, split_idx, instruction, answer\n",
    "    \"\"\"\n",
    "    # TODO: Implement this function\n",
    "    pass\n",
    "\n",
    "\n",
    "# Test your function\n",
    "# df_training = generate_training_dataset(dm, data_splitter, converter)\n",
    "# print(f\"Generated {len(df_training)} training examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47",
   "metadata": {},
   "source": [
    "---\n",
    "## üèÜ Challenge Complete!\n",
    "\n",
    "Congratulations on completing Challenge 1! You've learned how to:\n",
    "\n",
    "- ‚úÖ Explore and understand clinical data formats\n",
    "- ‚úÖ Configure the TwinWeaver pipeline for different tasks\n",
    "- ‚úÖ Generate training splits from patient timelines\n",
    "- ‚úÖ Convert data to instruction-tuning format\n",
    "- ‚úÖ Reverse convert predictions back to structured data\n",
    "\n",
    "Ready for the next challenge? Move on to **Challenge 2: End-to-End LLM Fine-tuning!**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
